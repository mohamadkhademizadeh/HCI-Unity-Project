{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# VR/AR Interaction Study \u2014 Analysis Notebook\n\nThis notebook computes descriptive stats, **paired t-tests**, **effect sizes** (Cohen's d), and summarizes **SUS** and **NASA\u2011TLX** for **gaze vs. joystick** conditions.\n\n> Fill in or replace `data_template.csv` with your actual data and re-run."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Setup\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n\n# Try to import scipy; if unavailable, fall back to manual t-tests\ntry:\n    from scipy import stats\n    SCIPY_OK = True\nexcept Exception:\n    SCIPY_OK = False\n\ndata_path = Path('/mnt/data/hci_vr_ar_project/data_template.csv')\ndf = pd.read_csv(data_path)\nprint(df.head())\n\n# Basic cleaning\ndf['condition'] = df['condition'].str.lower().str.strip()\ndf['hit'] = df['hit'].astype(int)\ndf['selection_time_ms'] = pd.to_numeric(df['selection_time_ms'], errors='coerce')\ndf['errors'] = pd.to_numeric(df['errors'], errors='coerce')\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Aggregate per participant & condition\nagg = df.groupby(['participant_id','condition']).agg(\n    mean_time_ms=('selection_time_ms','mean'),\n    median_time_ms=('selection_time_ms','median'),\n    error_rate=('errors', lambda x: np.sum(x)/max(len(x),1))\n).reset_index()\n\n# Wide format for paired tests\nwide_time = agg.pivot(index='participant_id', columns='condition', values='mean_time_ms')\nwide_error = agg.pivot(index='participant_id', columns='condition', values='error_rate')\n\ndisplay(agg.head())\nprint(\"\\nWide (time):\\n\", wide_time.head())\nprint(\"\\nWide (error):\\n\", wide_error.head())\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Helper: paired t-test with effect size\ndef paired_test(x, y, label):\n    x = pd.to_numeric(x, errors='coerce').dropna()\n    y = pd.to_numeric(y, errors='coerce').dropna()\n    common = x.index.intersection(y.index)\n    x = x.loc[common]\n    y = y.loc[common]\n    diff = x - y\n    n = len(diff)\n    if n < 2:\n        print(f'Not enough data for paired test on {label}.')\n        return None\n    if SCIPY_OK:\n        t, p = stats.ttest_rel(x, y, nan_policy='omit')\n    else:\n        # manual paired t-test\n        mean_diff = diff.mean()\n        sd_diff = diff.std(ddof=1)\n        t = mean_diff / (sd_diff / np.sqrt(n))\n        # two-tailed p-value via normal approx (fallback)\n        from math import erf, sqrt\n        p = 2 * (1 - 0.5*(1+erf(abs(t)/sqrt(2))))\n    # Cohen's d for paired samples (dz)\n    dz = diff.mean() / diff.std(ddof=1)\n    print(f\"{label}: n={n}, t={t:.3f}, p={p:.4f}, Cohen's dz={dz:.3f}\")\n    return {'n': n, 't': t, 'p': p, 'dz': dz}\n\nres_time = paired_test(wide_time.get('gaze'), wide_time.get('joystick'), 'Mean time (ms): gaze vs joystick')\nres_error = paired_test(wide_error.get('gaze'), wide_error.get('joystick'), 'Error rate: gaze vs joystick')\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# SUS scoring (0-100). We expect columns sus_q1..sus_q10 per row.\ndef compute_sus(row):\n    pos = [1,3,5,7,9]\n    neg = [2,4,6,8,10]\n    score = 0\n    for i in pos:\n        score += (row[f'sus_q{i}'] - 1)\n    for i in neg:\n        score += (5 - row[f'sus_q{i}'])\n    return score * 2.5\n\n# Compute per participant per condition SUS (if present)\nif all(col in df.columns for col in [f'sus_q{i}' for i in range(1,11)]):\n    sus = df.groupby(['participant_id','condition']).apply(lambda g: compute_sus(g.iloc[0])).reset_index(name='sus_score')\n    wide_sus = sus.pivot(index='participant_id', columns='condition', values='sus_score')\n    res_sus = None\n    if 'gaze' in wide_sus and 'joystick' in wide_sus:\n        res_sus = (wide_sus['gaze'] - wide_sus['joystick']).describe()\n        print(\"\\nSUS summary (gaze - joystick):\\n\", res_sus)\nelse:\n    print(\"SUS columns not found; skipping SUS scoring.\")\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# NASA-TLX summary (0-100 per subscale)\nnasatlx_cols = ['nasatlx_mental','nasatlx_physical','nasatlx_temporal','nasatlx_performance','nasatlx_effort','nasatlx_frustration']\nif all(c in df.columns for c in nasatlx_cols):\n    ntlx = df.groupby(['participant_id','condition'])[nasatlx_cols].mean().reset_index()\n    display(ntlx.head())\nelse:\n    print(\"NASA-TLX columns not found; skipping NASATLX summary.\")\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Plots (Matplotlib, one chart per figure, default colors)\n# Time by condition\ncond_time = agg.groupby('condition')['mean_time_ms'].mean().reset_index()\nplt.figure()\nplt.bar(cond_time['condition'], cond_time['mean_time_ms'])\nplt.title('Mean Selection Time by Condition')\nplt.xlabel('Condition')\nplt.ylabel('Time (ms)')\nplt.show()\n\n# Error rate by condition\ncond_error = agg.groupby('condition')['error_rate'].mean().reset_index()\nplt.figure()\nplt.bar(cond_error['condition'], cond_error['error_rate'])\nplt.title('Mean Error Rate by Condition')\nplt.xlabel('Condition')\nplt.ylabel('Error Rate')\nplt.show()\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}