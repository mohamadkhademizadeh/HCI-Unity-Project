# Comparing Gaze vs. Joystick for Target Selection in VR/AR

**Author:** <Your Name>  
**Date:** 2025-07-30

## Abstract
Briefly summarize the problem, method (within-subjects, N≈10–16), key results (times, errors, SUS, NASA‑TLX), and implications.

## 1. Introduction
- Motivation for comparing gaze and joystick.
- Prior work (cite a few key HCI/VR selection papers).
- Hypotheses (e.g., H1: Gaze yields faster time; H2: Joystick yields fewer errors; H3: Perceived workload lower for <X>).

## 2. Methods
### 2.1 Prototype & Apparatus
- Unity 2025, XR Interaction Toolkit; Meta Quest (or specify).
- Scene: grid of targets; dwell-based gaze selection; joystick‑reticle selection.
- Logging: CSV logger (times, errors), post‑task questionnaires.

### 2.2 Design
- Within-subjects; factors: **Condition** ∈ {Gaze, Joystick}; counterbalanced order (AB/BA).
- Tasks: select highlighted targets as they appear (scripted sequence).
- Dependent variables: completion time, error count, SUS, NASA‑TLX.
- Participants: N = 10–16; inclusion criteria; ethics/consent.

### 2.3 Procedure
- Briefing & consent → calibration → practice → two blocks (one per condition) → questionnaires → debrief.

## 3. Results
- Descriptives (M, SD) per condition.
- Paired t‑tests (time, errors, SUS, NASA‑TLX), Cohen’s d.
- Figures: bar charts with 95% CI.

## 4. Discussion
- Interpret differences; tradeoffs between speed and accuracy.
- Design recommendations for when to prefer gaze vs. joystick.
- Limitations (sample size, device); future work.

## 5. Conclusion
One paragraph summarizing practical guidance.

## References
- Add references here.

## Appendix
- Task scripts, counterbalancing table, inclusion/exclusion rules.
